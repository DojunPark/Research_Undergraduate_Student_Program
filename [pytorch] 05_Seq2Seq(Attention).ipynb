{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code by Tae Hwan Jung @graykode\n",
    "# Reference : https://github.com/hunkim/PyTorchZeroToAll/blob/master/14_2_seq2seq_att.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "\n",
    "def make_batch():\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = torch.empty([n_step, 1, n_class])\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = torch.zeros(n_step)  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dojun Park\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "n_step = 5 # number of cells(= number of Step)\n",
    "n_hidden = 128 # number of hidden units in one cell\n",
    "\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list\n",
    "\n",
    "# hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "hidden = torch.zeros(1, 1, n_hidden)\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dojun Park\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000502\n",
      "Epoch: 0800 cost = 0.000164\n",
      "Epoch: 1200 cost = 0.000082\n",
      "Epoch: 1600 cost = 0.000049\n",
      "Epoch: 2000 cost = 0.000032\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dojun Park\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "test_batch = torch.FloatTensor(test_batch)\n",
    "predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
    "\n",
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attn, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
